---
title: Building a Multi-Agent System for Real-Time Conversations Between Humans and Als
summary: This is an internship project at UC Berkeley and Nexa Speech, under the supervision of @NexaSpeech Lorenz Pichler and Alessandro Neri, made by Hin Chi Kwok, Kai Qin, Jaiteg Chahal, Nick Angelici, Nicole Han, and Ediz Ertekin.

tags:
  - Software Engineering
  - Machine Learning
date: '2024-04-28T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: 'https://www.nexa-speech.com'

image:
  caption: The diagram of architecture of the system design
  focal_point: Smart

# links:
#   - icon: twitter
#     icon_pack: fab
#     name: Follow
#     url: https://twitter.com/kwokhinchi
url_code: 'https://github.com/Nexa-speech'
url_pdf: 'https://drive.google.com/file/d/1Kqh5CEjUZe2LkTmn4JR83g1s4JD28NmT/view?usp=sharing'
# url_slides: 'https://docs.google.com/presentation/d/1OBVJ07WXGzge9d-UZCD76Cx5bwoX6Va_/edit?usp=drive_link&ouid=102358073185606588058&rtpof=true&sd=true'
# url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: example
---

<!-- Nowadays, with the advancement of production technologies, the manufacturing paradigm has gradually shifted from mass production to a small-batch and high-variety personalized production manner, urged by high flexible automation capabilities. In this paradigm, the existing inspection and assembly processes after manufacturing still rely to a large extent on either human operators with low efficiency or machines with low flexibility. To solve this issue, human-robot collaboration (HRC) has been a prevailing topic of recent concerns. Current robot control strategies in human-machine collaboration are mainly through pre-defined programming and do not yet meet the need for flexible and adaptable tasks in individualised production. To address this challenge, this paper proposes a deep reinforcement learning (DRL) approach based on metalearning to drive robots in HRC. It enables collaborative robots (cobots) to acquire basic skills and perform tasks based on personalised production requirements, improving learning efficiency and thus quickly adapting to new tasks for human operators. The robot control task was carried out in a simulated environment taken from a real production scenario to assess its efficacy. Experimental results show that our proposed method enables the robot to learn and perform HRC tasks quickly and outperforms the baseline DRL method in terms of success rate. -->


Al and LLMs have shown significant advancements in natural language understanding and generation. However, there is still a gap in the market for a comprehensive solution that can effectively synthesize information from multiple sources and present it in an intuitive, user-friendly manner.

The project aims to create a unified product that enables agent-to-agent interaction. This 'Al reporter' will be capable of analyzing articles stored in a database, extracting relevant information, and presenting it to the end user in a clear, concise, and visually appealing manner based on their specific queries. To enhance the user experience (UX) of the conversation, the system will incorporate speech generation and captions, making the interaction more engaging and accessible.
